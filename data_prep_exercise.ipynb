{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /Users/ramirolopez/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('all')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://codeup.edu/blog/'\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/20100101 Firefox/91.0\"}\n",
    "codeup_request = requests.get(base_url, headers=headers)\n",
    "soup = BeautifulSoup(codeup_request.text, 'html.parser')\n",
    "blog_links = [element['href'] for element in soup.find_all('a', class_='more-link')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets iterate through those blog links an build out a structure\n",
    "# that will allow me to scrape the contents of that page\n",
    "all_blogs = []\n",
    "for link in blog_links:\n",
    "    # get a response from the link element\n",
    "    response = requests.get(link, headers={'User-Agent': 'Robinson Rulez lol'})\n",
    "    #turn the response text into a soup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #grab the html element associated with the article body\n",
    "    title = soup.find('h1', class_='entry-title').text\n",
    "    #grab the html element associated with the article head\n",
    "    body = soup.find('div', class_='entry-content').text.strip()\n",
    "    # toss those two things with labels into a dictionary\n",
    "    row = {'title': title, 'article': body}\n",
    "    #add that dictionary to a list of dictionaries\n",
    "    all_blogs.append(row)\n",
    "#outside the loop:\n",
    "# cast the list of dictionaries into a pandas DataFrame\n",
    "articles = pd.DataFrame(all_blogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>May is traditionally known as Asian American a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Sarah Mellor</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Sarah Mell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Madeleine ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Madeleine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "3   Women in Tech: Panelist Spotlight – Sarah Mellor   \n",
       "4  Women in Tech: Panelist Spotlight – Madeleine ...   \n",
       "5  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "\n",
       "                                             article  \n",
       "0  May is traditionally known as Asian American a...  \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...  \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...  \n",
       "3  Women in tech: Panelist Spotlight – Sarah Mell...  \n",
       "4  Women in tech: Panelist Spotlight – Madeleine ...  \n",
       "5  Black excellence in tech: Panelist Spotlight –...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697575846.3459892"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://inshorts.com/en/read/'\n",
    "categories = [\n",
    "    'business',\n",
    "    'entertainment',\n",
    "    'technology',\n",
    "    'sports'\n",
    "]\n",
    "test_soup = BeautifulSoup(requests.get(base_url+categories[0]).text, 'html.parser')\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing contents for business.\n",
      "Time to grab contents of business: 0.18 seconds\n",
      "Grabbing contents for entertainment.\n",
      "Time to grab contents of entertainment: 0.08 seconds\n",
      "Grabbing contents for technology.\n",
      "Time to grab contents of technology: 0.09 seconds\n",
      "Grabbing contents for sports.\n",
      "Time to grab contents of sports: 0.17 seconds\n",
      "Job finished!\n",
      "It took 0.01 minutes to execute scraping\n"
     ]
    }
   ],
   "source": [
    "all_articles = pd.DataFrame(columns=['title', 'body','category'])\n",
    "t_sum = 0\n",
    "for category in categories:\n",
    "    t_0 = time.time()\n",
    "    print(f'Grabbing contents for {category}.')\n",
    "    # construct a url based on our base concatenated with the cat\n",
    "    category_url = base_url + category\n",
    "    # get the response text from the constructed url\n",
    "    raw_content = requests.get(category_url).text\n",
    "    #turn the content into soup:\n",
    "    soup = BeautifulSoup(raw_content, 'html.parser')\n",
    "    # title content:\n",
    "    titles = [\n",
    "        element.text for element in soup.find_all(\n",
    "            'span', itemprop='headline')\n",
    "    ]\n",
    "    # body content:\n",
    "    bodies = [\n",
    "        element.text for element in soup.find_all(\n",
    "            'div', itemprop='articleBody')\n",
    "    ]\n",
    "    # category (its already here :) ) \n",
    "    category_df = pd.DataFrame(\n",
    "    {\n",
    "        'title': titles,\n",
    "        'body': bodies,\n",
    "        'category': category\n",
    "    })\n",
    "    all_articles = pd.concat(\n",
    "    [\n",
    "        all_articles,\n",
    "        category_df\n",
    "    ],\n",
    "    axis=0,\n",
    "    ignore_index=True)\n",
    "    t_n = time.time()\n",
    "    t_delta = t_n - t_0\n",
    "    print(f'Time to grab contents of {category}: {round(t_delta, 2)} seconds')\n",
    "    t_sum += t_delta\n",
    "print('Job finished!')\n",
    "print(f'It took {round((t_sum / 60), 2)} minutes to execute scraping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victoria's Secret ex-CEO cuts Harvard ties for...</td>\n",
       "      <td>Victoria's Secret ex-CEO Leslie Wexner's found...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDFC Bank's Vigil Aunty ad gets criticism for ...</td>\n",
       "      <td>HDFC Bank's latest advertisement featuring Vig...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMEC big opportunity for investors to partner ...</td>\n",
       "      <td>PM Narendra Modi at the Global Maritime India ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICICI Bank fined ₹12 crore, Kotak ₹3.95 crore ...</td>\n",
       "      <td>The Reserve Bank of India (RBI) has imposed a ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35 lakh weddings in 23 days to generate record...</td>\n",
       "      <td>Traders' body Confederation of All India Trade...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mahadev app key accused arrives from Dubai, he...</td>\n",
       "      <td>Mrugank Mishra, a key accused in Mahadev betti...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bankman-Fried's trial delay request over Adder...</td>\n",
       "      <td>A US court denied FTX Founder Sam Bankman-Frie...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indian wheat prices hit 8-month high</td>\n",
       "      <td>Prices of wheat in India have reached an eight...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dabur gets ₹321 crore GST demand notice</td>\n",
       "      <td>Dabur India has received a notice to pay Goods...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'Kill list' of LinkedIn staff being fired was ...</td>\n",
       "      <td>A list with names of about 500 employees was l...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Planned to make 'Jab...' with Bobby, 'Highway'...</td>\n",
       "      <td>Filmmaker Imtiaz Ali revealed that he was plan...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ranbir asks photographers to be careful as the...</td>\n",
       "      <td>Veteran actress Waheeda Rehman was honoured wi...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Don't break your bank: Zeenat to youngsters on...</td>\n",
       "      <td>Actress Zeenat Aman took to Instagram to share...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'Kabhi Khushi...' had really bad reviews, I wa...</td>\n",
       "      <td>Filmmaker Karan Johar said that he was \"very d...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Emotional moment: Sandeepa on visiting Kashmir...</td>\n",
       "      <td>Actress Sandeepa Dhar, who was just two when h...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Won't work with Sivakarthikeyan again, he betr...</td>\n",
       "      <td>Music composer D Imman said that he will never...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What a shame, I'm going to erase today: Direct...</td>\n",
       "      <td>Filmmaker and gay rights activist Onir, expres...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kriti Sanon, Allu Arjun's selfie in 'Pushpa' p...</td>\n",
       "      <td>Kriti Sanon received the Best Actress award at...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Taylor Swift's Eras tour security guard joins ...</td>\n",
       "      <td>A security guard who provided protection to si...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pics show Alia, Ranbir, Kriti, Allu Arjun inte...</td>\n",
       "      <td>The 69th National Film Awards ceremony was hel...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Palestinian, Arab, Muslim Googlers deeply affe...</td>\n",
       "      <td>Google CEO Sundar Pichai in an e-mail to emplo...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Russia fines Zoom $1.18mn for working without ...</td>\n",
       "      <td>Russia has imposed a $1.18 million fine on Zoo...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>US restricts sale of more advanced AI chips to...</td>\n",
       "      <td>The US on Tuesday unveiled plans to restrict t...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Apple unveils new Pencil with USB-C port costi...</td>\n",
       "      <td>Apple on Tuesday unveiled the new Apple Pencil...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Apple's cheaper headset to have less sensors, ...</td>\n",
       "      <td>Apple is reportedly planning to use fewer exte...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dubai Police unveils driverless, AI-powered pa...</td>\n",
       "      <td>Dubai Police has unveiled a \"self-driving\" pat...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bankman-Fried's trial delay request over Adder...</td>\n",
       "      <td>A US court denied FTX Founder Sam Bankman-Frie...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'Apple AirTag led to multiple murders,' claims...</td>\n",
       "      <td>Apple is facing a class action lawsuit in US t...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'Kill list' of LinkedIn staff being fired was ...</td>\n",
       "      <td>A list with names of about 500 employees was l...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Facebook, YouTube, Google suppress pro-Palesti...</td>\n",
       "      <td>Think tank Hampton Institute alleged that soci...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Netherlands defeat South Africa in another ups...</td>\n",
       "      <td>Netherlands, the lowest-ranked team in the ong...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>People would tell my parents 'Don't allow her ...</td>\n",
       "      <td>Table tennis player Sutirtha Mukherjee, who al...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Are Netherlands doing them in again: Harsha on...</td>\n",
       "      <td>Commentator Harsha Bhogle took to X to state t...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Rishabh Pant shares video of him running on tr...</td>\n",
       "      <td>Wicketkeeper-batter Rishabh Pant, who is under...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Sri Lanka Cricket lifts ban on Gunathilaka aft...</td>\n",
       "      <td>Sri Lanka Cricket (SLC) has lifted ban on Danu...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Exceptional bowling: Uthappa as SA lose 4 batt...</td>\n",
       "      <td>Reacting to South Africa losing four batters w...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PCB files complaint over crowd conduct against...</td>\n",
       "      <td>The PCB has filed a complaint regarding inappr...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Game vs SA could be over before powerplay if E...</td>\n",
       "      <td>Former England batter Mark Butcher said Englan...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I have never seen Rauf pick wickets like Bumra...</td>\n",
       "      <td>Ex-Pakistan captain Wasim Akram said he has ne...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3 of Netherlands' cricketers playing against S...</td>\n",
       "      <td>Netherlands' Sybrand Engelbrecht, Colin Ackerm...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Victoria's Secret ex-CEO cuts Harvard ties for...   \n",
       "1   HDFC Bank's Vigil Aunty ad gets criticism for ...   \n",
       "2   IMEC big opportunity for investors to partner ...   \n",
       "3   ICICI Bank fined ₹12 crore, Kotak ₹3.95 crore ...   \n",
       "4   35 lakh weddings in 23 days to generate record...   \n",
       "5   Mahadev app key accused arrives from Dubai, he...   \n",
       "6   Bankman-Fried's trial delay request over Adder...   \n",
       "7                Indian wheat prices hit 8-month high   \n",
       "8             Dabur gets ₹321 crore GST demand notice   \n",
       "9   'Kill list' of LinkedIn staff being fired was ...   \n",
       "10  Planned to make 'Jab...' with Bobby, 'Highway'...   \n",
       "11  Ranbir asks photographers to be careful as the...   \n",
       "12  Don't break your bank: Zeenat to youngsters on...   \n",
       "13  'Kabhi Khushi...' had really bad reviews, I wa...   \n",
       "14  Emotional moment: Sandeepa on visiting Kashmir...   \n",
       "15  Won't work with Sivakarthikeyan again, he betr...   \n",
       "16  What a shame, I'm going to erase today: Direct...   \n",
       "17  Kriti Sanon, Allu Arjun's selfie in 'Pushpa' p...   \n",
       "18  Taylor Swift's Eras tour security guard joins ...   \n",
       "19  Pics show Alia, Ranbir, Kriti, Allu Arjun inte...   \n",
       "20  Palestinian, Arab, Muslim Googlers deeply affe...   \n",
       "21  Russia fines Zoom $1.18mn for working without ...   \n",
       "22  US restricts sale of more advanced AI chips to...   \n",
       "23  Apple unveils new Pencil with USB-C port costi...   \n",
       "24  Apple's cheaper headset to have less sensors, ...   \n",
       "25  Dubai Police unveils driverless, AI-powered pa...   \n",
       "26  Bankman-Fried's trial delay request over Adder...   \n",
       "27  'Apple AirTag led to multiple murders,' claims...   \n",
       "28  'Kill list' of LinkedIn staff being fired was ...   \n",
       "29  Facebook, YouTube, Google suppress pro-Palesti...   \n",
       "30  Netherlands defeat South Africa in another ups...   \n",
       "31  People would tell my parents 'Don't allow her ...   \n",
       "32  Are Netherlands doing them in again: Harsha on...   \n",
       "33  Rishabh Pant shares video of him running on tr...   \n",
       "34  Sri Lanka Cricket lifts ban on Gunathilaka aft...   \n",
       "35  Exceptional bowling: Uthappa as SA lose 4 batt...   \n",
       "36  PCB files complaint over crowd conduct against...   \n",
       "37  Game vs SA could be over before powerplay if E...   \n",
       "38  I have never seen Rauf pick wickets like Bumra...   \n",
       "39  3 of Netherlands' cricketers playing against S...   \n",
       "\n",
       "                                                 body       category  \n",
       "0   Victoria's Secret ex-CEO Leslie Wexner's found...       business  \n",
       "1   HDFC Bank's latest advertisement featuring Vig...       business  \n",
       "2   PM Narendra Modi at the Global Maritime India ...       business  \n",
       "3   The Reserve Bank of India (RBI) has imposed a ...       business  \n",
       "4   Traders' body Confederation of All India Trade...       business  \n",
       "5   Mrugank Mishra, a key accused in Mahadev betti...       business  \n",
       "6   A US court denied FTX Founder Sam Bankman-Frie...       business  \n",
       "7   Prices of wheat in India have reached an eight...       business  \n",
       "8   Dabur India has received a notice to pay Goods...       business  \n",
       "9   A list with names of about 500 employees was l...       business  \n",
       "10  Filmmaker Imtiaz Ali revealed that he was plan...  entertainment  \n",
       "11  Veteran actress Waheeda Rehman was honoured wi...  entertainment  \n",
       "12  Actress Zeenat Aman took to Instagram to share...  entertainment  \n",
       "13  Filmmaker Karan Johar said that he was \"very d...  entertainment  \n",
       "14  Actress Sandeepa Dhar, who was just two when h...  entertainment  \n",
       "15  Music composer D Imman said that he will never...  entertainment  \n",
       "16  Filmmaker and gay rights activist Onir, expres...  entertainment  \n",
       "17  Kriti Sanon received the Best Actress award at...  entertainment  \n",
       "18  A security guard who provided protection to si...  entertainment  \n",
       "19  The 69th National Film Awards ceremony was hel...  entertainment  \n",
       "20  Google CEO Sundar Pichai in an e-mail to emplo...     technology  \n",
       "21  Russia has imposed a $1.18 million fine on Zoo...     technology  \n",
       "22  The US on Tuesday unveiled plans to restrict t...     technology  \n",
       "23  Apple on Tuesday unveiled the new Apple Pencil...     technology  \n",
       "24  Apple is reportedly planning to use fewer exte...     technology  \n",
       "25  Dubai Police has unveiled a \"self-driving\" pat...     technology  \n",
       "26  A US court denied FTX Founder Sam Bankman-Frie...     technology  \n",
       "27  Apple is facing a class action lawsuit in US t...     technology  \n",
       "28  A list with names of about 500 employees was l...     technology  \n",
       "29  Think tank Hampton Institute alleged that soci...     technology  \n",
       "30  Netherlands, the lowest-ranked team in the ong...         sports  \n",
       "31  Table tennis player Sutirtha Mukherjee, who al...         sports  \n",
       "32  Commentator Harsha Bhogle took to X to state t...         sports  \n",
       "33  Wicketkeeper-batter Rishabh Pant, who is under...         sports  \n",
       "34  Sri Lanka Cricket (SLC) has lifted ban on Danu...         sports  \n",
       "35  Reacting to South Africa losing four batters w...         sports  \n",
       "36  The PCB has filed a complaint regarding inappr...         sports  \n",
       "37  Former England batter Mark Butcher said Englan...         sports  \n",
       "38  Ex-Pakistan captain Wasim Akram said he has ne...         sports  \n",
       "39  Netherlands' Sybrand Engelbrecht, Colin Ackerm...         sports  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "## Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'lopez.j.ramiro1@gmail.com is my - Email. (678)937-1910 is my Phone #.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lopez.j.ramiro1@gmail.com is my - email. (678)937-1910 is my phone #.\n"
     ]
    }
   ],
   "source": [
    "# made everything lowercase\n",
    "test_string = test_string.lower()\n",
    "print(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lopezjramiro1gmailcom is my  email 6789371910 is my phone \n"
     ]
    }
   ],
   "source": [
    "# replaced anything that is not a letter, number, whitespace or single quite. \n",
    "test_string = re.sub(r\"[^a-z0-9'\\s]\", '', test_string)\n",
    "print(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lopezjramiro1gmailcom is my  email 6789371910 is my phone \n"
     ]
    }
   ],
   "source": [
    "# normalize unicode characters \n",
    "test_string = unicodedata.normalize('NFKD', test_string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "print(test_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(paragraph):\n",
    "    paragraph = paragraph.lower()\n",
    "    paragraph = re.sub(r\"[^a-z0-9'\\s]\", '', paragraph)\n",
    "    paragraph = unicodedata.normalize('NFKD', paragraph)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('may is traditionally known as asian american and pacific islander aapi '\n",
      " 'heritage month this month we celebrate the history and contributions made '\n",
      " 'possible by our aapi friends family and community we also examine our level '\n",
      " 'of support and seek opportunities to better understand the aapi community\\n'\n",
      " '\\n'\n",
      " 'in an effort to address real concerns and experiences we sat down with '\n",
      " 'arbeena thapa one of codeups financial aid and enrollment managers\\n'\n",
      " 'arbeena identifies as nepali american and desi arbeenas parents immigrated '\n",
      " 'to texas in 1988 for better employment and educational opportunities '\n",
      " 'arbeenas older sister was five when they made the move to the us arbeena was '\n",
      " 'born later becoming the first in her family to be a us citizen\\n'\n",
      " 'at codeup we take our efforts at inclusivity very seriously after speaking '\n",
      " 'with arbeena we were taught that the term aapi excludes desiamerican '\n",
      " 'individuals hence we will now use the term asian pacific islander desi '\n",
      " 'american apida\\n'\n",
      " 'here is how the rest of our conversation with arbeena went\\n'\n",
      " 'how do you celebrate or connect with your heritage and cultural traditions\\n'\n",
      " 'i celebrate nepals version of christmas or dashain this is a nineday '\n",
      " 'celebration also known as dussehra i grew up as hindu and i identify as '\n",
      " 'hindu this is a very large part of my heritage \\n'\n",
      " 'other ways i connect with my culture include sharing food momos are south '\n",
      " 'asian dumplings and theyre my favorite to make and share\\n'\n",
      " 'on my asian american side i am an advocate of immigrant justice and erasure '\n",
      " 'within apida social or political movements i participate in events to '\n",
      " 'embrace my identity such as immigrant justice advocacy because i come from a '\n",
      " 'mixedstatus family ive always been in a community with undocumented asian '\n",
      " 'immigrants \\n'\n",
      " 'what are some of the challenges you have faced as an apida individual '\n",
      " 'personally or professionally\\n'\n",
      " 'i often struggle with being gendered as compliant or a pushover '\n",
      " 'professionally i am often stereotyped as meek so ive been overlooked for '\n",
      " 'leadership roles we are seen as perpetually foreign people tend to other us '\n",
      " 'in that way yet put us on a pedestal for what a model minority looks like '\n",
      " 'this has made me hesitant to share my heritage in the past because these '\n",
      " 'assumptions get mapped onto me \\n'\n",
      " 'can you describe some common barriers of entry that apida individuals '\n",
      " 'specifically women may face when trying to enter or advance in the '\n",
      " 'workplace\\n'\n",
      " 'being overlooked for leadership in the past i have not been viewed as a '\n",
      " 'leader people sometimes have preconceived stereotypes of asian women not '\n",
      " 'being able to be bold or being vocal can be mistaken for being too '\n",
      " 'emotional \\n'\n",
      " 'how do you believe microaggressions impact apida individuals in the '\n",
      " 'workplace can you provide examples of such microaggressions\\n'\n",
      " 'erasure is big to me only saying merry christmas isnt inclusive to other '\n",
      " 'religions people are often resistant to saying happy holidays but saying '\n",
      " 'merry christmas excludes and does not appreciate my heritage \\n'\n",
      " 'often microaggressions are not micro at all they typically are not '\n",
      " 'aggressive racialized violence but the term micro minimizes impact\\n'\n",
      " 'some that ive heard are what kind of asian are you or where are you from '\n",
      " 'this automatically makes me the other and not seen as american even within '\n",
      " 'the apida community south asians are overlooked as asian\\n'\n",
      " 'how important is representation specifically apida representation in '\n",
      " 'organizational leadership positions\\n'\n",
      " 'i want to say that it is important to have someone who looks like you in '\n",
      " 'leadership roles and it is but those leaders may not share the same beliefs '\n",
      " 'as you certain privileges such as wealth resources or lack of interaction '\n",
      " 'with lowersocioeconomicstatus asian americans may cause a difference in '\n",
      " 'community politics i do not think the bamboo ceiling is acceptable but the '\n",
      " 'company you work for plays a big part in your politics and belief alignment\\n'\n",
      " 'how do you feel about codeswitching and have you ever felt it necessary to '\n",
      " 'codeswitch\\n'\n",
      " 'i like sharing south asian terms or connecting with others that have similar '\n",
      " 'heritage and culture a workplace that is welcoming to going into this sort '\n",
      " 'of breakout is refreshing and makes space for us however having to '\n",
      " 'codeswitch could also mean a workplace that is not conducive and welcoming '\n",
      " 'of other cultures \\n'\n",
      " 'finally in your opinion what longterm strategies can create lasting change '\n",
      " 'in the workplace and ensure support equality and inclusion for apida '\n",
      " 'individuals\\n'\n",
      " 'prior to a career in financial aid i did a lot of research related to the '\n",
      " 'post911 immigration of the south asian diaspora this background made me '\n",
      " 'heavily rely on grassroots organizing hire the people that want to innovate '\n",
      " 'hire the changemakers hire the buttonpushers reduce reliance on whiteness as '\n",
      " 'change this will become natural for the organization and become '\n",
      " 'organizational change change comes from us on the ground\\n'\n",
      " 'a huge thank you to arbeena thapa for sharing her experiences and being '\n",
      " 'vulnerable with us your words were inspiring and the opportunity to '\n",
      " 'understand your perspective more has been valuable we hope we can become '\n",
      " 'better support for the apida community as we learn and grow on our journey '\n",
      " 'of cultivating inclusive growth')\n",
      " \n",
      "================================================================================\n",
      " \n",
      "('women in tech panelist spotlight  magdalena rahn\\n'\n",
      " 'codeup is hosting a women in tech panel in honor of womens history month on '\n",
      " 'march 29th 2023 to further celebrate wed like to spotlight each of our '\n",
      " 'panelists leading up to the discussion to learn a bit about their respective '\n",
      " 'experiences as women in the tech industry\\n'\n",
      " '\\n'\n",
      " 'meet magdalena\\n'\n",
      " 'magdalena rahn is a current codeup student in a data science cohort in san '\n",
      " 'antonio texas she has a professional background in crosscultural '\n",
      " 'communications international business development the wine industry and '\n",
      " 'journalism after serving in the us navy she decided to complement her '\n",
      " 'professional skill set by attending the data science program at codeup she '\n",
      " 'is set to graduate in march 2023 magdalena is fluent in french bulgarian '\n",
      " 'chinesemandarin spanish and italian\\n'\n",
      " 'we asked magdalena how codeup impacted her career and she replied codeup has '\n",
      " 'provided a solid foundation in analytical processes programming and data '\n",
      " 'science methods and its been an encouragement to have such supportive '\n",
      " 'instructors and wonderful classmates\\n'\n",
      " 'dont forget to tune in on march 29th to sit in on an insightful conversation '\n",
      " 'with magdalena')\n",
      " \n",
      "================================================================================\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# test on code up blog article \n",
    "sep_line = \"=\" * 80\n",
    "for art in articles.article[:2]:\n",
    "    pprint(basic_clean(art))\n",
    "    print(' ')\n",
    "    print(sep_line)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "## Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May is traditionally known as Asian American and Pacific Islander ( AAPI ) Heritage Month. This month we celebrate the history and contributions made possible by our AAPI friends , family , and community. We also examine our level of support and seek opportunities to better understand the AAPI community.\n",
      "\n",
      "In an effort to address real concerns and experiences , we sat down with Arbeena Thapa , one of Codeup ’ s Financial Aid and Enrollment Managers.\n",
      "Arbeena identifies as Nepali American and Desi.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(articles.article[0], return_str=True)[0:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(paragraph):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return tokenizer.tokenize(paragraph, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Women in tech : Panelist Spotlight – Madeleine Capper\\nCodeup is hosting a Women in Tech Panel in honor of Women ’ s History Month on March 29th , 2023 ! To further celebrate , we ’ d like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as women in the tech industry ! \\nMeet Madeleine ! \\nMadeleine Capper is a Data Scientist in San Antonio , Texas. A long-standing San Antonio resident , she studied mathematics at the University of Texas San Antonio and has worked as a Data Scientist for Booz Allen Hamilton. Madeleine currently teaches Data Science at Codeup , where she works daily with burgeoning data professionals to help them actualize their career aspirations through technical education.\\nMadeleine attended Codeup as a student in early 2019 as a pupil in the very first Codeup Data Science cohort. The program proved immediately effective and she was the first student to obtain a data career out of the program. After working at Booz Allen Hamilton , Madeleine ’ s passion for education in conjunction with her appreciation for Codeup ’ s capacity for transformative life change brought her back to the institution in an instructional capacity , where she has been teaching for two years.\\nDon ’ t forget to tune in on March 29th to sit in on an insightful conversation .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(articles.article[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "### Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "ps = nltk.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may is tradit known as asian american and pacif island (aapi) heritag month. thi month we celebr the histori and contribut made possibl by our aapi friends, family, and community. we also examin our level of support and seek opportun to better understand the aapi community. in an effort to address real concern and experiences, we sat down with arbeena thapa, one of codeup’ financi aid and enrol managers. arbeena identifi as nepali american and desi. arbeena’ parent immigr to texa in 1988 for better employ and educ opportunities. arbeena’ older sister wa five when they made the move to the us. arbeena wa born later, becom the first in her famili to be a us citizen. at codeup we take our effort at inclus veri seriously. after speak with arbeena, we were taught that the term aapi exclud desi-american individuals. hence, we will now use the term asian pacif island desi american (apida). here is how the rest of our convers with arbeena went! how do you celebr or connect with your heritag and cultur traditions? “i celebr nepal’ version of christma or dashain. thi is a nine-day celebr also known as dussehra. i grew up as hindu and i identifi as hindu, thi is a veri larg part of my heritage. “ “other way i connect with my cultur includ share food! momo are south asian dumpl and they’r my favorit to make and share.” “on my asian american side, i am an advoc of immigr justic and erasur within apida social or polit movements. i particip in event to embrac my ident such as immigr justic advocaci becaus i come from a mixed-statu family. i’v alway been in a commun with undocu asian immigrants. .” what are some of the challeng you have face as an apida individual, person or professionally? “i often struggl with be gender as compliant or a pushover. professionally, i am often stereotyp as meek, so i’v been overlook for leadership roles. we are seen as perpetu foreign; peopl tend to other us in that way, yet put us on a pedest for what a model minor look like. thi ha made me hesit to share my heritag in the past becaus these assumpt get map onto me. ” can you describ some common barrier of entri that apida individuals, specif women may face when tri to enter or advanc in the workplace? “be overlook for leadership. in the past, i have not been view as a leader. peopl sometim have preconceiv stereotyp of asian women not be abl to be bold, or be vocal can be mistaken for be too emotional. “ how do you believ microaggress impact apida individu in the workplace? can you provid exampl of such microaggressions? “erasur is big. to me, onli say ‘merri christmas’ isn’t inclus to other religions. peopl are often resist to say ‘happi holidays,’ but say merri christma excludes, and doe not appreci my heritage. “ “often microaggress are not micro at all. they typic are not aggress racial violence, but the term ‘micro’ minim impact.” “some that i’v heard are ‘what kind of asian are you?’ or ‘where are you from?’ thi automat make me the ‘other’ and not seen as american. even within the apida community, south asian are overlook as “asian”.” how import is representation, specif apida representation, in organiz leadership positions? “i want to say that it is import to have someon who look like you in leadership roles, and it is, but those leader may not share the same belief as you. certain privileg such as wealth, resources, or lack of interact with lower-socioeconomic-statu asian american may caus a differ in commun politics. i do not think the bamboo ceil is acceptable, but the compani you work for play a big part in your polit and belief alignment.” how do you feel about code-switching, and have you ever felt it necessari to code-switch? “i like share south asian term or connect with other that have similar heritag and culture. a workplac that is welcom to go into thi sort of breakout is refresh and make space for us. however, have to code-switch could also mean a workplac that is not conduc and welcom of other cultures. “ finally, in your opinion, what long-term strategi can creat last chang in the workplac and ensur support, equality, and inclus for apida individuals? “prior to a career in financi aid, i did a lot of research relat to the post-9/11 immigr of the south asian diaspora. thi background made me heavili reli on grassroot organizing. hire the peopl that want to innovate, hire the changemakers, hire the button-pushers. reduc relianc on white as change. thi will becom natur for the organ and becom organiz change. chang come from us on the ground.” a huge thank you to arbeena thapa for share her experiences, and be vulner with us. your word were inspir and the opportun to understand your perspect more ha been valuable. we hope we can becom better support for the apida commun as we learn and grow on our journey of cultiv inclus growth.\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in articles.article[0].split()]\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(article_stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the      29\n",
       "and      27\n",
       "to       24\n",
       "as       17\n",
       "in       17\n",
       "of       17\n",
       "a        16\n",
       "is       11\n",
       "for      11\n",
       "asian    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(paragraph):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in paragraph.split()]\n",
    "    paragraph_stemmed = ' '.join(stems)\n",
    "    return paragraph_stemmed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_one = stem(articles.article[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n",
    "### Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = articles.article[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May\n",
      "is\n",
      "traditionally\n",
      "known\n",
      "a\n",
      "Asian\n",
      "American\n",
      "and\n",
      "Pacific\n",
      "Islander\n",
      "(AAPI)\n",
      "Heritage\n",
      "Month.\n",
      "This\n",
      "month\n",
      "we\n",
      "celebrate\n",
      "the\n",
      "history\n",
      "and\n",
      "contribution\n",
      "made\n",
      "possible\n",
      "by\n",
      "our\n",
      "AAPI\n",
      "friends,\n",
      "family,\n",
      "and\n",
      "community.\n",
      "We\n",
      "also\n",
      "examine\n",
      "our\n",
      "level\n",
      "of\n",
      "support\n",
      "and\n",
      "seek\n",
      "opportunity\n",
      "to\n",
      "better\n",
      "understand\n",
      "the\n",
      "AAPI\n",
      "community.\n",
      "In\n",
      "an\n",
      "effort\n",
      "to\n",
      "address\n",
      "real\n",
      "concern\n",
      "and\n",
      "experiences,\n",
      "we\n",
      "sat\n",
      "down\n",
      "with\n",
      "Arbeena\n",
      "Thapa,\n",
      "one\n",
      "of\n",
      "Codeup’s\n",
      "Financial\n",
      "Aid\n",
      "and\n",
      "Enrollment\n",
      "Managers.\n",
      "Arbeena\n",
      "identifies\n",
      "a\n",
      "Nepali\n",
      "American\n",
      "and\n",
      "Desi.\n",
      "Arbeena’s\n",
      "parent\n",
      "immigrated\n",
      "to\n",
      "Texas\n",
      "in\n",
      "1988\n",
      "for\n",
      "better\n",
      "employment\n",
      "and\n",
      "educational\n",
      "opportunities.\n",
      "Arbeena’s\n",
      "older\n",
      "sister\n",
      "wa\n",
      "five\n",
      "when\n",
      "they\n",
      "made\n",
      "the\n",
      "move\n",
      "to\n",
      "the\n",
      "US.\n",
      "Arbeena\n",
      "wa\n",
      "born\n",
      "later,\n",
      "becoming\n",
      "the\n",
      "first\n",
      "in\n",
      "her\n",
      "family\n",
      "to\n",
      "be\n",
      "a\n",
      "US\n",
      "citizen.\n",
      "At\n",
      "Codeup\n",
      "we\n",
      "take\n",
      "our\n",
      "effort\n",
      "at\n",
      "inclusivity\n",
      "very\n",
      "seriously.\n",
      "After\n",
      "speaking\n",
      "with\n",
      "Arbeena,\n",
      "we\n",
      "were\n",
      "taught\n",
      "that\n",
      "the\n",
      "term\n",
      "AAPI\n",
      "excludes\n",
      "Desi-American\n",
      "individuals.\n",
      "Hence,\n",
      "we\n",
      "will\n",
      "now\n",
      "use\n",
      "the\n",
      "term\n",
      "Asian\n",
      "Pacific\n",
      "Islander\n",
      "Desi\n",
      "American\n",
      "(APIDA).\n",
      "Here\n",
      "is\n",
      "how\n",
      "the\n",
      "rest\n",
      "of\n",
      "our\n",
      "conversation\n",
      "with\n",
      "Arbeena\n",
      "went!\n",
      "How\n",
      "do\n",
      "you\n",
      "celebrate\n",
      "or\n",
      "connect\n",
      "with\n",
      "your\n",
      "heritage\n",
      "and\n",
      "cultural\n",
      "traditions?\n",
      "“I\n",
      "celebrate\n",
      "Nepal’s\n",
      "version\n",
      "of\n",
      "Christmas\n",
      "or\n",
      "Dashain.\n",
      "This\n",
      "is\n",
      "a\n",
      "nine-day\n",
      "celebration\n",
      "also\n",
      "known\n",
      "a\n",
      "Dussehra.\n",
      "I\n",
      "grew\n",
      "up\n",
      "a\n",
      "Hindu\n",
      "and\n",
      "I\n",
      "identify\n",
      "a\n",
      "Hindu,\n",
      "this\n",
      "is\n",
      "a\n",
      "very\n",
      "large\n",
      "part\n",
      "of\n",
      "my\n",
      "heritage.\n",
      "“\n",
      "“Other\n",
      "way\n",
      "I\n",
      "connect\n",
      "with\n",
      "my\n",
      "culture\n",
      "include\n",
      "sharing\n",
      "food!\n",
      "Momos\n",
      "are\n",
      "South\n",
      "Asian\n",
      "Dumplings\n",
      "and\n",
      "they’re\n",
      "my\n",
      "favorite\n",
      "to\n",
      "make\n",
      "and\n",
      "share.”\n",
      "“On\n",
      "my\n",
      "Asian\n",
      "American\n",
      "side,\n",
      "I\n",
      "am\n",
      "an\n",
      "advocate\n",
      "of\n",
      "immigrant\n",
      "justice\n",
      "and\n",
      "erasure\n",
      "within\n",
      "APIDA\n",
      "social\n",
      "or\n",
      "political\n",
      "movements.\n",
      "I\n",
      "participate\n",
      "in\n",
      "event\n",
      "to\n",
      "embrace\n",
      "my\n",
      "identity\n",
      "such\n",
      "a\n",
      "immigrant\n",
      "justice\n",
      "advocacy\n",
      "because\n",
      "I\n",
      "come\n",
      "from\n",
      "a\n",
      "mixed-status\n",
      "family.\n",
      "I’ve\n",
      "always\n",
      "been\n",
      "in\n",
      "a\n",
      "community\n",
      "with\n",
      "undocumented\n",
      "Asian\n",
      "immigrants.\n",
      ".”\n",
      "What\n",
      "are\n",
      "some\n",
      "of\n",
      "the\n",
      "challenge\n",
      "you\n",
      "have\n",
      "faced\n",
      "a\n",
      "an\n",
      "APIDA\n",
      "individual,\n",
      "personally\n",
      "or\n",
      "professionally?\n",
      "“I\n",
      "often\n",
      "struggle\n",
      "with\n",
      "being\n",
      "gendered\n",
      "a\n",
      "compliant\n",
      "or\n",
      "a\n",
      "pushover.\n",
      "Professionally,\n",
      "I\n",
      "am\n",
      "often\n",
      "stereotyped\n",
      "a\n",
      "meek,\n",
      "so\n",
      "I’ve\n",
      "been\n",
      "overlooked\n",
      "for\n",
      "leadership\n",
      "roles.\n",
      "We\n",
      "are\n",
      "seen\n",
      "a\n",
      "perpetually\n",
      "foreign;\n",
      "people\n",
      "tend\n",
      "to\n",
      "other\n",
      "u\n",
      "in\n",
      "that\n",
      "way,\n",
      "yet\n",
      "put\n",
      "u\n",
      "on\n",
      "a\n",
      "pedestal\n",
      "for\n",
      "what\n",
      "a\n",
      "model\n",
      "minority\n",
      "look\n",
      "like.\n",
      "This\n",
      "ha\n",
      "made\n",
      "me\n",
      "hesitant\n",
      "to\n",
      "share\n",
      "my\n",
      "heritage\n",
      "in\n",
      "the\n",
      "past\n",
      "because\n",
      "these\n",
      "assumption\n",
      "get\n",
      "mapped\n",
      "onto\n",
      "me.\n",
      "”\n",
      "Can\n",
      "you\n",
      "describe\n",
      "some\n",
      "common\n",
      "barrier\n",
      "of\n",
      "entry\n",
      "that\n",
      "APIDA\n",
      "individuals,\n",
      "specifically\n",
      "woman\n",
      "may\n",
      "face\n",
      "when\n",
      "trying\n",
      "to\n",
      "enter\n",
      "or\n",
      "advance\n",
      "in\n",
      "the\n",
      "workplace?\n",
      "“Being\n",
      "overlooked\n",
      "for\n",
      "leadership.\n",
      "In\n",
      "the\n",
      "past,\n",
      "I\n",
      "have\n",
      "not\n",
      "been\n",
      "viewed\n",
      "a\n",
      "a\n",
      "leader.\n",
      "People\n",
      "sometimes\n",
      "have\n",
      "preconceived\n",
      "stereotype\n",
      "of\n",
      "Asian\n",
      "woman\n",
      "not\n",
      "being\n",
      "able\n",
      "to\n",
      "be\n",
      "bold,\n",
      "or\n",
      "being\n",
      "vocal\n",
      "can\n",
      "be\n",
      "mistaken\n",
      "for\n",
      "being\n",
      "too\n",
      "emotional.\n",
      "“\n",
      "How\n",
      "do\n",
      "you\n",
      "believe\n",
      "microaggressions\n",
      "impact\n",
      "APIDA\n",
      "individual\n",
      "in\n",
      "the\n",
      "workplace?\n",
      "Can\n",
      "you\n",
      "provide\n",
      "example\n",
      "of\n",
      "such\n",
      "microaggressions?\n",
      "“Erasure\n",
      "is\n",
      "big.\n",
      "To\n",
      "me,\n",
      "only\n",
      "saying\n",
      "‘Merry\n",
      "Christmas’\n",
      "isn’t\n",
      "inclusive\n",
      "to\n",
      "other\n",
      "religions.\n",
      "People\n",
      "are\n",
      "often\n",
      "resistant\n",
      "to\n",
      "saying\n",
      "‘Happy\n",
      "Holidays,’\n",
      "but\n",
      "saying\n",
      "Merry\n",
      "Christmas\n",
      "excludes,\n",
      "and\n",
      "doe\n",
      "not\n",
      "appreciate\n",
      "my\n",
      "heritage.\n",
      "“\n",
      "“Often\n",
      "microaggressions\n",
      "are\n",
      "not\n",
      "micro\n",
      "at\n",
      "all.\n",
      "They\n",
      "typically\n",
      "are\n",
      "not\n",
      "aggressive\n",
      "racialized\n",
      "violence,\n",
      "but\n",
      "the\n",
      "term\n",
      "‘micro’\n",
      "minimizes\n",
      "impact.”\n",
      "“Some\n",
      "that\n",
      "I’ve\n",
      "heard\n",
      "are\n",
      "‘What\n",
      "kind\n",
      "of\n",
      "Asian\n",
      "are\n",
      "you?’\n",
      "or\n",
      "‘Where\n",
      "are\n",
      "you\n",
      "from?’\n",
      "This\n",
      "automatically\n",
      "make\n",
      "me\n",
      "the\n",
      "‘other’\n",
      "and\n",
      "not\n",
      "seen\n",
      "a\n",
      "American.\n",
      "Even\n",
      "within\n",
      "the\n",
      "APIDA\n",
      "community,\n",
      "South\n",
      "Asians\n",
      "are\n",
      "overlooked\n",
      "a\n",
      "“Asian”.”\n",
      "How\n",
      "important\n",
      "is\n",
      "representation,\n",
      "specifically\n",
      "APIDA\n",
      "representation,\n",
      "in\n",
      "organizational\n",
      "leadership\n",
      "positions?\n",
      "“I\n",
      "want\n",
      "to\n",
      "say\n",
      "that\n",
      "it\n",
      "is\n",
      "important\n",
      "to\n",
      "have\n",
      "someone\n",
      "who\n",
      "look\n",
      "like\n",
      "you\n",
      "in\n",
      "leadership\n",
      "roles,\n",
      "and\n",
      "it\n",
      "is,\n",
      "but\n",
      "those\n",
      "leader\n",
      "may\n",
      "not\n",
      "share\n",
      "the\n",
      "same\n",
      "belief\n",
      "a\n",
      "you.\n",
      "Certain\n",
      "privilege\n",
      "such\n",
      "a\n",
      "wealth,\n",
      "resources,\n",
      "or\n",
      "lack\n",
      "of\n",
      "interaction\n",
      "with\n",
      "lower-socioeconomic-status\n",
      "Asian\n",
      "Americans\n",
      "may\n",
      "cause\n",
      "a\n",
      "difference\n",
      "in\n",
      "community\n",
      "politics.\n",
      "I\n",
      "do\n",
      "not\n",
      "think\n",
      "the\n",
      "bamboo\n",
      "ceiling\n",
      "is\n",
      "acceptable,\n",
      "but\n",
      "the\n",
      "company\n",
      "you\n",
      "work\n",
      "for\n",
      "play\n",
      "a\n",
      "big\n",
      "part\n",
      "in\n",
      "your\n",
      "politics\n",
      "and\n",
      "belief\n",
      "alignment.”\n",
      "How\n",
      "do\n",
      "you\n",
      "feel\n",
      "about\n",
      "code-switching,\n",
      "and\n",
      "have\n",
      "you\n",
      "ever\n",
      "felt\n",
      "it\n",
      "necessary\n",
      "to\n",
      "code-switch?\n",
      "“I\n",
      "like\n",
      "sharing\n",
      "South\n",
      "Asian\n",
      "term\n",
      "or\n",
      "connecting\n",
      "with\n",
      "others\n",
      "that\n",
      "have\n",
      "similar\n",
      "heritage\n",
      "and\n",
      "culture.\n",
      "A\n",
      "workplace\n",
      "that\n",
      "is\n",
      "welcoming\n",
      "to\n",
      "going\n",
      "into\n",
      "this\n",
      "sort\n",
      "of\n",
      "breakout\n",
      "is\n",
      "refreshing\n",
      "and\n",
      "make\n",
      "space\n",
      "for\n",
      "us.\n",
      "However,\n",
      "having\n",
      "to\n",
      "code-switch\n",
      "could\n",
      "also\n",
      "mean\n",
      "a\n",
      "workplace\n",
      "that\n",
      "is\n",
      "not\n",
      "conducive\n",
      "and\n",
      "welcoming\n",
      "of\n",
      "other\n",
      "cultures.\n",
      "“\n",
      "Finally,\n",
      "in\n",
      "your\n",
      "opinion,\n",
      "what\n",
      "long-term\n",
      "strategy\n",
      "can\n",
      "create\n",
      "lasting\n",
      "change\n",
      "in\n",
      "the\n",
      "workplace\n",
      "and\n",
      "ensure\n",
      "support,\n",
      "equality,\n",
      "and\n",
      "inclusion\n",
      "for\n",
      "APIDA\n",
      "individuals?\n",
      "“Prior\n",
      "to\n",
      "a\n",
      "career\n",
      "in\n",
      "financial\n",
      "aid,\n",
      "I\n",
      "did\n",
      "a\n",
      "lot\n",
      "of\n",
      "research\n",
      "related\n",
      "to\n",
      "the\n",
      "post-9/11\n",
      "immigration\n",
      "of\n",
      "the\n",
      "South\n",
      "Asian\n",
      "diaspora.\n",
      "This\n",
      "background\n",
      "made\n",
      "me\n",
      "heavily\n",
      "rely\n",
      "on\n",
      "grassroots\n",
      "organizing.\n",
      "Hire\n",
      "the\n",
      "people\n",
      "that\n",
      "want\n",
      "to\n",
      "innovate,\n",
      "hire\n",
      "the\n",
      "changemakers,\n",
      "hire\n",
      "the\n",
      "button-pushers.\n",
      "Reduce\n",
      "reliance\n",
      "on\n",
      "whiteness\n",
      "a\n",
      "change.\n",
      "This\n",
      "will\n",
      "become\n",
      "natural\n",
      "for\n",
      "the\n",
      "organization\n",
      "and\n",
      "become\n",
      "organizational\n",
      "change.\n",
      "Change\n",
      "come\n",
      "from\n",
      "u\n",
      "on\n",
      "the\n",
      "ground.”\n",
      "A\n",
      "huge\n",
      "thank\n",
      "you\n",
      "to\n",
      "Arbeena\n",
      "Thapa\n",
      "for\n",
      "sharing\n",
      "her\n",
      "experiences,\n",
      "and\n",
      "being\n",
      "vulnerable\n",
      "with\n",
      "us.\n",
      "Your\n",
      "word\n",
      "were\n",
      "inspiring\n",
      "and\n",
      "the\n",
      "opportunity\n",
      "to\n",
      "understand\n",
      "your\n",
      "perspective\n",
      "more\n",
      "ha\n",
      "been\n",
      "valuable.\n",
      "We\n",
      "hope\n",
      "we\n",
      "can\n",
      "become\n",
      "better\n",
      "support\n",
      "for\n",
      "the\n",
      "APIDA\n",
      "community\n",
      "a\n",
      "we\n",
      "learn\n",
      "and\n",
      "grow\n",
      "on\n",
      "our\n",
      "journey\n",
      "of\n",
      "cultivating\n",
      "inclusive\n",
      "growth.\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "for word in test_string.split():\n",
    "    print(wnl.lemmatize(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May is traditionally known a Asian American and Pacific Islander (AAPI) Heritage Month. This month we celebrate the history and contribution made possible by our AAPI friends, family, and community. We also examine our level of support and seek opportunity to better understand the AAPI community. In an effort to address real concern and experiences, we sat down with Arbeena Thapa, one of Codeup’s Financial Aid and Enrollment Managers. Arbeena identifies a Nepali American and Desi. Arbeena’s parent immigrated to Texas in 1988 for better employment and educational opportunities. Arbeena’s older sister wa five when they made the move to the US. Arbeena wa born later, becoming the first in her family to be a US citizen. At Codeup we take our effort at inclusivity very seriously. After speaking with Arbeena, we were taught that the term AAPI excludes Desi-American individuals. Hence, we will now use the term Asian Pacific Islander Desi American (APIDA). Here is how the rest of our conversation with Arbeena went! How do you celebrate or connect with your heritage and cultural traditions? “I celebrate Nepal’s version of Christmas or Dashain. This is a nine-day celebration also known a Dussehra. I grew up a Hindu and I identify a Hindu, this is a very large part of my heritage. “ “Other way I connect with my culture include sharing food! Momos are South Asian Dumplings and they’re my favorite to make and share.” “On my Asian American side, I am an advocate of immigrant justice and erasure within APIDA social or political movements. I participate in event to embrace my identity such a immigrant justice advocacy because I come from a mixed-status family. I’ve always been in a community with undocumented Asian immigrants. .” What are some of the challenge you have faced a an APIDA individual, personally or professionally? “I often struggle with being gendered a compliant or a pushover. Professionally, I am often stereotyped a meek, so I’ve been overlooked for leadership roles. We are seen a perpetually foreign; people tend to other u in that way, yet put u on a pedestal for what a model minority look like. This ha made me hesitant to share my heritage in the past because these assumption get mapped onto me. ” Can you describe some common barrier of entry that APIDA individuals, specifically woman may face when trying to enter or advance in the workplace? “Being overlooked for leadership. In the past, I have not been viewed a a leader. People sometimes have preconceived stereotype of Asian woman not being able to be bold, or being vocal can be mistaken for being too emotional. “ How do you believe microaggressions impact APIDA individual in the workplace? Can you provide example of such microaggressions? “Erasure is big. To me, only saying ‘Merry Christmas’ isn’t inclusive to other religions. People are often resistant to saying ‘Happy Holidays,’ but saying Merry Christmas excludes, and doe not appreciate my heritage. “ “Often microaggressions are not micro at all. They typically are not aggressive racialized violence, but the term ‘micro’ minimizes impact.” “Some that I’ve heard are ‘What kind of Asian are you?’ or ‘Where are you from?’ This automatically make me the ‘other’ and not seen a American. Even within the APIDA community, South Asians are overlooked a “Asian”.” How important is representation, specifically APIDA representation, in organizational leadership positions? “I want to say that it is important to have someone who look like you in leadership roles, and it is, but those leader may not share the same belief a you. Certain privilege such a wealth, resources, or lack of interaction with lower-socioeconomic-status Asian Americans may cause a difference in community politics. I do not think the bamboo ceiling is acceptable, but the company you work for play a big part in your politics and belief alignment.” How do you feel about code-switching, and have you ever felt it necessary to code-switch? “I like sharing South Asian term or connecting with others that have similar heritage and culture. A workplace that is welcoming to going into this sort of breakout is refreshing and make space for us. However, having to code-switch could also mean a workplace that is not conducive and welcoming of other cultures. “ Finally, in your opinion, what long-term strategy can create lasting change in the workplace and ensure support, equality, and inclusion for APIDA individuals? “Prior to a career in financial aid, I did a lot of research related to the post-9/11 immigration of the South Asian diaspora. This background made me heavily rely on grassroots organizing. Hire the people that want to innovate, hire the changemakers, hire the button-pushers. Reduce reliance on whiteness a change. This will become natural for the organization and become organizational change. Change come from u on the ground.” A huge thank you to Arbeena Thapa for sharing her experiences, and being vulnerable with us. Your word were inspiring and the opportunity to understand your perspective more ha been valuable. We hope we can become better support for the APIDA community a we learn and grow on our journey of cultivating inclusive growth.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a      31\n",
       "the    29\n",
       "and    27\n",
       "to     23\n",
       "of     17\n",
       "in     15\n",
       "for    11\n",
       "is     11\n",
       "you    11\n",
       "or     10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in test_string.split()]\n",
    "article_lemmatized = ' '.join(lemmas)\n",
    "\n",
    "print(article_lemmatized)\n",
    "\n",
    "pd.Series(lemmas).value_counts()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmonize(paragraph):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in paragraph.split()]\n",
    "    article_lemmatized = ' '.join(lemmas)\n",
    "    return article_lemmatized\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Women in tech: Panelist Spotlight – Magdalena Rahn Codeup is hosting a Women in Tech Panel in honor of Women’s History Month on March 29th, 2023! To further celebrate, we’d like to spotlight each of our panelist leading up to the discussion to learn a bit about their respective experience a woman in the tech industry! Meet Magdalena! Magdalena Rahn is a current Codeup student in a Data Science cohort in San Antonio, Texas. She ha a professional background in cross-cultural communications, international business development, the wine industry and journalism. After serving in the US Navy, she decided to complement her professional skill set by attending the Data Science program at Codeup; she is set to graduate in March 2023. Magdalena is fluent in French, Bulgarian, Chinese-Mandarin, Spanish and Italian. We asked Magdalena how Codeup impacted her career, and she replied “Codeup ha provided a solid foundation in analytical processes, programming and data science methods, and it’s been an encouragement to have such supportive instructor and wonderful classmates.” Don’t forget to tune in on March 29th to sit in on an insightful conversation with Magdalena.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmonize(articles.article[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5\n",
    "### Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "- This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "stopword_list[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 333 stopwords\n",
      "---\n",
      "May traditionally known Asian American Pacific Islander (AAPI) Heritage Month. This month celebrate history contributions made possible AAPI friends, family, community. We also examine level support seek opportunities better understand AAPI community. In effort address real concerns experiences, sat Arbeena Thapa, one Codeup’s Financial Aid Enrollment Managers. Arbeena identifies Nepali American Desi. Arbeena’s parents immigrated Texas 1988 better employment educational opportunities. Arbeena’s older sister five made move US. Arbeena born later, becoming first family US citizen. At Codeup take efforts inclusivity seriously. After speaking Arbeena, taught term AAPI excludes Desi-American individuals. Hence, use term Asian Pacific Islander Desi American (APIDA). Here rest conversation Arbeena went! How celebrate connect heritage cultural traditions? “I celebrate Nepal’s version Christmas Dashain. This nine-day celebration also known Dussehra. I grew Hindu I identify Hindu, large part heritage. “ “Other ways I connect culture include sharing food! Momos South Asian Dumplings they’re favorite make share.” “On Asian American side, I advocate immigrant justice erasure within APIDA social political movements. I participate events embrace identity immigrant justice advocacy I come mixed-status family. I’ve always community undocumented Asian immigrants. .” What challenges faced APIDA individual, personally professionally? “I often struggle gendered compliant pushover. Professionally, I often stereotyped meek, I’ve overlooked leadership roles. We seen perpetually foreign; people tend us way, yet put us pedestal model minority looks like. This made hesitant share heritage past assumptions get mapped onto me. ” Can describe common barriers entry APIDA individuals, specifically women may face trying enter advance workplace? “Being overlooked leadership. In past, I not viewed leader. People sometimes preconceived stereotypes Asian women not able bold, vocal mistaken emotional. “ How believe microaggressions impact APIDA individuals workplace? Can provide examples microaggressions? “Erasure big. To me, saying ‘Merry Christmas’ isn’t inclusive religions. People often resistant saying ‘Happy Holidays,’ saying Merry Christmas excludes, not appreciate heritage. “ “Often microaggressions not micro all. They typically not aggressive racialized violence, term ‘micro’ minimizes impact.” “Some I’ve heard ‘What kind Asian you?’ ‘Where from?’ This automatically makes ‘other’ not seen American. Even within APIDA community, South Asians overlooked “Asian”.” How important representation, specifically APIDA representation, organizational leadership positions? “I want say important someone looks like leadership roles, is, leaders may not share beliefs you. Certain privileges wealth, resources, lack interaction lower-socioeconomic-status Asian Americans may cause difference community politics. I not think bamboo ceiling acceptable, company work plays big part politics belief alignment.” How feel code-switching, ever felt necessary code-switch? “I like sharing South Asian terms connecting others similar heritage culture. A workplace welcoming going sort breakout refreshing makes space us. However, code-switch could also mean workplace not conducive welcoming cultures. “ Finally, opinion, long-term strategies create lasting change workplace ensure support, equality, inclusion APIDA individuals? “Prior career financial aid, I lot research related post-9/11 immigration South Asian diaspora. This background made heavily rely grassroots organizing. Hire people want innovate, hire changemakers, hire button-pushers. Reduce reliance whiteness change. This become natural organization become organizational change. Change comes us ground.” A huge thank Arbeena Thapa sharing experiences, vulnerable us. Your words inspiring opportunity understand perspective valuable. We hope become better support APIDA community learn grow journey cultivating inclusive growth.\n"
     ]
    }
   ],
   "source": [
    "words = test_string.split()\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "print('---')\n",
    "\n",
    "article_without_stopwords = ' '.join(filtered_words)\n",
    "\n",
    "print(article_without_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victoria's Secret ex-CEO cuts Harvard ties for...</td>\n",
       "      <td>Victoria's Secret ex-CEO Leslie Wexner's found...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDFC Bank's Vigil Aunty ad gets criticism for ...</td>\n",
       "      <td>HDFC Bank's latest advertisement featuring Vig...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMEC big opportunity for investors to partner ...</td>\n",
       "      <td>PM Narendra Modi at the Global Maritime India ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICICI Bank fined ₹12 crore, Kotak ₹3.95 crore ...</td>\n",
       "      <td>The Reserve Bank of India (RBI) has imposed a ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35 lakh weddings in 23 days to generate record...</td>\n",
       "      <td>Traders' body Confederation of All India Trade...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Victoria's Secret ex-CEO cuts Harvard ties for...   \n",
       "1  HDFC Bank's Vigil Aunty ad gets criticism for ...   \n",
       "2  IMEC big opportunity for investors to partner ...   \n",
       "3  ICICI Bank fined ₹12 crore, Kotak ₹3.95 crore ...   \n",
       "4  35 lakh weddings in 23 days to generate record...   \n",
       "\n",
       "                                                body  category  \n",
       "0  Victoria's Secret ex-CEO Leslie Wexner's found...  business  \n",
       "1  HDFC Bank's latest advertisement featuring Vig...  business  \n",
       "2  PM Narendra Modi at the Global Maritime India ...  business  \n",
       "3  The Reserve Bank of India (RBI) has imposed a ...  business  \n",
       "4  Traders' body Confederation of All India Trade...  business  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles['clean'] = all_articles['body'].apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victoria's Secret ex-CEO cuts Harvard ties for...</td>\n",
       "      <td>Victoria's Secret ex-CEO Leslie Wexner's found...</td>\n",
       "      <td>business</td>\n",
       "      <td>victoria's secret exceo leslie wexner's founda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDFC Bank's Vigil Aunty ad gets criticism for ...</td>\n",
       "      <td>HDFC Bank's latest advertisement featuring Vig...</td>\n",
       "      <td>business</td>\n",
       "      <td>hdfc bank's latest advertisement featuring vig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMEC big opportunity for investors to partner ...</td>\n",
       "      <td>PM Narendra Modi at the Global Maritime India ...</td>\n",
       "      <td>business</td>\n",
       "      <td>pm narendra modi at the global maritime india ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Victoria's Secret ex-CEO cuts Harvard ties for...   \n",
       "1  HDFC Bank's Vigil Aunty ad gets criticism for ...   \n",
       "2  IMEC big opportunity for investors to partner ...   \n",
       "\n",
       "                                                body  category  \\\n",
       "0  Victoria's Secret ex-CEO Leslie Wexner's found...  business   \n",
       "1  HDFC Bank's latest advertisement featuring Vig...  business   \n",
       "2  PM Narendra Modi at the Global Maritime India ...  business   \n",
       "\n",
       "                                               clean  \n",
       "0  victoria's secret exceo leslie wexner's founda...  \n",
       "1  hdfc bank's latest advertisement featuring vig...  \n",
       "2  pm narendra modi at the global maritime india ...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles['stemmed'] =all_articles['body'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victoria's Secret ex-CEO cuts Harvard ties for...</td>\n",
       "      <td>Victoria's Secret ex-CEO Leslie Wexner's found...</td>\n",
       "      <td>business</td>\n",
       "      <td>victoria's secret exceo leslie wexner's founda...</td>\n",
       "      <td>victoria' secret ex-ceo lesli wexner' foundat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDFC Bank's Vigil Aunty ad gets criticism for ...</td>\n",
       "      <td>HDFC Bank's latest advertisement featuring Vig...</td>\n",
       "      <td>business</td>\n",
       "      <td>hdfc bank's latest advertisement featuring vig...</td>\n",
       "      <td>hdfc bank' latest advertis featur vigil aunti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMEC big opportunity for investors to partner ...</td>\n",
       "      <td>PM Narendra Modi at the Global Maritime India ...</td>\n",
       "      <td>business</td>\n",
       "      <td>pm narendra modi at the global maritime india ...</td>\n",
       "      <td>pm narendra modi at the global maritim india s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Victoria's Secret ex-CEO cuts Harvard ties for...   \n",
       "1  HDFC Bank's Vigil Aunty ad gets criticism for ...   \n",
       "2  IMEC big opportunity for investors to partner ...   \n",
       "\n",
       "                                                body  category  \\\n",
       "0  Victoria's Secret ex-CEO Leslie Wexner's found...  business   \n",
       "1  HDFC Bank's latest advertisement featuring Vig...  business   \n",
       "2  PM Narendra Modi at the Global Maritime India ...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  victoria's secret exceo leslie wexner's founda...   \n",
       "1  hdfc bank's latest advertisement featuring vig...   \n",
       "2  pm narendra modi at the global maritime india ...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  victoria' secret ex-ceo lesli wexner' foundat ...  \n",
       "1  hdfc bank' latest advertis featur vigil aunti ...  \n",
       "2  pm narendra modi at the global maritim india s...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles['lemmatizatized'] = all_articles['body'].apply(lemmonize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatizatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victoria's Secret ex-CEO cuts Harvard ties for...</td>\n",
       "      <td>Victoria's Secret ex-CEO Leslie Wexner's found...</td>\n",
       "      <td>business</td>\n",
       "      <td>victoria's secret exceo leslie wexner's founda...</td>\n",
       "      <td>victoria' secret ex-ceo lesli wexner' foundat ...</td>\n",
       "      <td>Victoria's Secret ex-CEO Leslie Wexner's found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDFC Bank's Vigil Aunty ad gets criticism for ...</td>\n",
       "      <td>HDFC Bank's latest advertisement featuring Vig...</td>\n",
       "      <td>business</td>\n",
       "      <td>hdfc bank's latest advertisement featuring vig...</td>\n",
       "      <td>hdfc bank' latest advertis featur vigil aunti ...</td>\n",
       "      <td>HDFC Bank's latest advertisement featuring Vig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMEC big opportunity for investors to partner ...</td>\n",
       "      <td>PM Narendra Modi at the Global Maritime India ...</td>\n",
       "      <td>business</td>\n",
       "      <td>pm narendra modi at the global maritime india ...</td>\n",
       "      <td>pm narendra modi at the global maritim india s...</td>\n",
       "      <td>PM Narendra Modi at the Global Maritime India ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Victoria's Secret ex-CEO cuts Harvard ties for...   \n",
       "1  HDFC Bank's Vigil Aunty ad gets criticism for ...   \n",
       "2  IMEC big opportunity for investors to partner ...   \n",
       "\n",
       "                                                body  category  \\\n",
       "0  Victoria's Secret ex-CEO Leslie Wexner's found...  business   \n",
       "1  HDFC Bank's latest advertisement featuring Vig...  business   \n",
       "2  PM Narendra Modi at the Global Maritime India ...  business   \n",
       "\n",
       "                                               clean  \\\n",
       "0  victoria's secret exceo leslie wexner's founda...   \n",
       "1  hdfc bank's latest advertisement featuring vig...   \n",
       "2  pm narendra modi at the global maritime india ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  victoria' secret ex-ceo lesli wexner' foundat ...   \n",
       "1  hdfc bank' latest advertis featur vigil aunti ...   \n",
       "2  pm narendra modi at the global maritim india s...   \n",
       "\n",
       "                                      lemmatizatized  \n",
       "0  Victoria's Secret ex-CEO Leslie Wexner's found...  \n",
       "1  HDFC Bank's latest advertisement featuring Vig...  \n",
       "2  PM Narendra Modi at the Global Maritime India ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>May is traditionally known as Asian American a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Sarah Mellor</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Sarah Mell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women in Tech: Panelist Spotlight – Madeleine ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Madeleine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "3   Women in Tech: Panelist Spotlight – Sarah Mellor   \n",
       "4  Women in Tech: Panelist Spotlight – Madeleine ...   \n",
       "\n",
       "                                             article  \n",
       "0  May is traditionally known as Asian American a...  \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...  \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...  \n",
       "3  Women in tech: Panelist Spotlight – Sarah Mell...  \n",
       "4  Women in tech: Panelist Spotlight – Madeleine ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['clean'] = articles['article'].apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>May is traditionally known as Asian American a...</td>\n",
       "      <td>may is traditionally known as asian american a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>women in tech panelist spotlight  magdalena ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>women in tech panelist spotlight  rachel robbi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "\n",
       "                                             article  \\\n",
       "0  May is traditionally known as Asian American a...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "\n",
       "                                               clean  \n",
       "0  may is traditionally known as asian american a...  \n",
       "1  women in tech panelist spotlight  magdalena ra...  \n",
       "2  women in tech panelist spotlight  rachel robbi...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['stemmed'] = articles['clean'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>May is traditionally known as Asian American a...</td>\n",
       "      <td>may is traditionally known as asian american a...</td>\n",
       "      <td>may is tradit known as asian american and paci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>women in tech panelist spotlight  magdalena ra...</td>\n",
       "      <td>women in tech panelist spotlight magdalena rah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>women in tech panelist spotlight  rachel robbi...</td>\n",
       "      <td>women in tech panelist spotlight rachel robbin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "\n",
       "                                             article  \\\n",
       "0  May is traditionally known as Asian American a...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  may is traditionally known as asian american a...   \n",
       "1  women in tech panelist spotlight  magdalena ra...   \n",
       "2  women in tech panelist spotlight  rachel robbi...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  may is tradit known as asian american and paci...  \n",
       "1  women in tech panelist spotlight magdalena rah...  \n",
       "2  women in tech panelist spotlight rachel robbin...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['lemmatizatized'] = articles['clean'].apply(lemmonize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatizatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>May is traditionally known as Asian American a...</td>\n",
       "      <td>may is traditionally known as asian american a...</td>\n",
       "      <td>may is tradit known as asian american and paci...</td>\n",
       "      <td>may is traditionally known a asian american an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>women in tech panelist spotlight  magdalena ra...</td>\n",
       "      <td>women in tech panelist spotlight magdalena rah...</td>\n",
       "      <td>woman in tech panelist spotlight magdalena rah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Rachel Rob...</td>\n",
       "      <td>women in tech panelist spotlight  rachel robbi...</td>\n",
       "      <td>women in tech panelist spotlight rachel robbin...</td>\n",
       "      <td>woman in tech panelist spotlight rachel robbin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "\n",
       "                                             article  \\\n",
       "0  May is traditionally known as Asian American a...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Women in tech: Panelist Spotlight – Rachel Rob...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  may is traditionally known as asian american a...   \n",
       "1  women in tech panelist spotlight  magdalena ra...   \n",
       "2  women in tech panelist spotlight  rachel robbi...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  may is tradit known as asian american and paci...   \n",
       "1  women in tech panelist spotlight magdalena rah...   \n",
       "2  women in tech panelist spotlight rachel robbin...   \n",
       "\n",
       "                                      lemmatizatized  \n",
       "0  may is traditionally known a asian american an...  \n",
       "1  woman in tech panelist spotlight magdalena rah...  \n",
       "2  woman in tech panelist spotlight rachel robbin...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
